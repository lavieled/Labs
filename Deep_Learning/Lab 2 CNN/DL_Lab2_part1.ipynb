{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Lab: ECE-00450107\n",
    "## Meeting 2 - Part 1: Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code in this file, make sure that you are **activating the enviourment** in which the following packages are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions and Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from collections import Counter\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "from DL_Lab2_functions import *\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "matplotlib.use('Agg')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Network (using VGG13), Classifing CIFAR10\n",
    "\n",
    "In this meeting we will implement and train a deep convolutional network, to classify the CIFAR10 dataset.\n",
    "CIFAR 10, as the name suggests, contains 10 classes of objects. Here are some sample images:\n",
    "<center><img src=\"assets/cifar10.jpeg\" width=\"400px\"></center>\n",
    "\n",
    "So... Let us start :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set fixed seeds to enable reproducing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Setting fixed seeds\n",
    "seed = 2025\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Training Data\n",
    "load the dataset and calculate mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The train set contains 50000 images, divided into 10 sections:\n",
      "Label 6: 5000 examples\n",
      "Label 9: 5000 examples\n",
      "Label 4: 5000 examples\n",
      "Label 1: 5000 examples\n",
      "Label 2: 5000 examples\n",
      "Label 7: 5000 examples\n",
      "Label 8: 5000 examples\n",
      "Label 3: 5000 examples\n",
      "Label 5: 5000 examples\n",
      "Label 0: 5000 examples\n",
      "The test set contains 10000 images, divided into 10 sections:\n",
      "Label 3: 1000 examples\n",
      "Label 8: 1000 examples\n",
      "Label 0: 1000 examples\n",
      "Label 6: 1000 examples\n",
      "Label 1: 1000 examples\n",
      "Label 9: 1000 examples\n",
      "Label 5: 1000 examples\n",
      "Label 7: 1000 examples\n",
      "Label 4: 1000 examples\n",
      "Label 2: 1000 examples\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.CIFAR10(root=\"/usr/share/DL_exp/datasets/cifar10\", train=True, download=True)\n",
    "test = torchvision.datasets.CIFAR10(root=\"/usr/share/DL_exp/datasets/cifar10\", train=False, download=True)\n",
    "class_names = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "\n",
    "# Count the number of samples in each category\n",
    "print(f\"The train set contains {train_size} images, divided into {len(class_names)} sections:\")\n",
    "labels = [label for _, label in train]\n",
    "label_counts = Counter(labels)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count} examples\")\n",
    "\n",
    "print(f\"The test set contains {test_size} images, divided into {len(class_names)} sections:\")\n",
    "labels = [label for _, label in test]\n",
    "label_counts = Counter(labels)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.491, 0.482, 0.447], std: [0.247, 0.243, 0.262]\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor(train.data).to(float())/255\n",
    "test_data = torch.tensor(test.data).to(float())/255\n",
    "\n",
    "mean_imn = torch.mean(train_data, dim=(0, 1, 2))\n",
    "std_imn = torch.std(train_data, dim=(0, 1, 2))\n",
    "print(f\"mean: {[round(value, 3) for value in mean_imn.tolist()]}, std: {[round(value, 3) for value in std_imn.tolist()]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the Test/Train Transformations\n",
    "Here we define the transformations that will be applied to the images during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_augmentataions = True\n",
    "if use_augmentataions:\n",
    "    augmentations = [transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "                    transforms.RandomHorizontalFlip()]\n",
    "    train.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean_imn, std=std_imn)] + augmentations)\n",
    "    test.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean_imn, std=std_imn)])\n",
    "else:\n",
    "    train.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean_imn, std=std_imn)])\n",
    "    test.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean_imn, std=std_imn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a VGG Block\n",
    "Define a single VGG block according to the specifications in the booklet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, c_in: int, c_out: int):\n",
    "        super(VGGBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels=c_in,out_channels=c_in,kernel_size=3,padding=1),  \n",
    "                                   nn.BatchNorm2d(num_features=c_in), # TODO: complete a batch normalization layer\n",
    "                                   nn.ReLU(), # TODO: complete an activation layer\n",
    "                                   nn.Conv2d(in_channels=c_in,out_channels=c_out,kernel_size=3,padding=1), # TODO: complete a convolution layer with kernel size 3x3 and padding size of 1\n",
    "                                   nn.BatchNorm2d(num_features=c_out), # TODO: complete a batch normalization layer\n",
    "                                   nn.ReLU(), # TODO: complete an activation layer\n",
    "                                   nn.MaxPool2d(kernel_size=2,stride=2)  # TODO: complete a max pooling layer with kernal size 2 and stride 2\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the VGG Network\n",
    "Now, we can define the entire network, based on blocks.  \n",
    "We will use 5 intermediate blocks, add a dropout layer, and lastly add a fully-connected layer at the end to classify the images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG13(nn.Module):\n",
    "    def __init__(self, input_channels: Tuple[int, ...], mid_channels: Tuple[int, ...], output_channels: int, p: float = 0):\n",
    "        super(VGG13, self).__init__()\n",
    "        self.vggblocks = nn.Sequential(VGGBlock(input_channels[0], mid_channels[0]),\n",
    "                                       VGGBlock(mid_channels[0], mid_channels[1]),\n",
    "                                       VGGBlock(mid_channels[1], mid_channels[2]),\n",
    "                                       VGGBlock(mid_channels[2], mid_channels[3]),\n",
    "                                       VGGBlock(mid_channels[3], mid_channels[4]))\n",
    "\n",
    "        # TODO: Define a dropout layer with probability p\n",
    "        self.dropout = nn.Dropout2d(p=p)\n",
    "        # TODO: Define the final linear layer\n",
    "        self.linear = nn.Linear(in_features=mid_channels[4],out_features=output_channels)\n",
    "        # TODO: Define a flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        # TODO: Define a softmax layer\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Complete the vggblocks sequence\n",
    "        z1 = self.vggblocks(x)\n",
    "        # TODO: Complete the dropout layer\n",
    "        z2 = self.dropout(z1)\n",
    "        # TODO: Complete the flatten of z2\n",
    "        z3 =  self.flatten(z2)\n",
    "        # TODO: Complete the final linear layer\n",
    "        z4 = self.linear(z3)\n",
    "        # TODO: Add softmax in the end\n",
    "        out = self.softmax(z4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Hyper-parameters\n",
    "Define the hyper-parameters for the training of the VGG13 network according to the specifications in the booklet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #Set device\n",
    "\n",
    "hparams = Hyper_Params()\n",
    "\n",
    "hparams.epochs = 40\n",
    "hparams.batch_size = 250\n",
    "\n",
    "hparams.lr = 0.001\n",
    "hparams.dropout_probability = 0\n",
    "hparams.scheduler_step_size = 8\n",
    "hparams.scheduler_factor = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up the Training Parameters\n",
    "Define the VGG13 model using the parameters specified in the booklet.\n",
    "In addition, define the scheduler, the optimizer and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG13(input_channels=(3, 32, 32),\n",
    "              mid_channels=[64, 128, 256, 512, 1024], # complete the values of the channels according to the network's definition in the booklet\n",
    "              output_channels=10,\n",
    "              p=hparams.dropout_probability).to(device) \n",
    "\n",
    "# TODO: Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hparams.lr)\n",
    "# TODO: Define the learning rate scheduler of type StepLR\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=hparams.scheduler_step_size, gamma=hparams.scheduler_factor)\n",
    "# TODO: Define the loss function using cross entropy\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define dataloaders for the train and test sets: we shall set the num_workers to 16 and use shuffle for training\n",
    "train_loader = DataLoader(train, batch_size=hparams.batch_size, shuffle=True, num_workers=16)\n",
    "test_loader = DataLoader(test, batch_size=hparams.batch_size, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Training Loop\n",
    "Complete the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_scheduler(hparams: Hyper_Params,\n",
    "                         train_loader: DataLoader,\n",
    "                         test_loader: DataLoader,\n",
    "                         model: nn.Module,\n",
    "                         optimizer: optim.Optimizer,\n",
    "                         scheduler: optim.lr_scheduler.LRScheduler,\n",
    "                         loss_function: nn.Module) -> None:\n",
    "    hparams.fig, (hparams.ax1, hparams.ax2) = plt.subplots(2, 1, figsize=(15, 9))\n",
    "    print_performance_grid(Flag=True)\n",
    "    iter_num = len(train_loader)\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    start_time = time.time() # time the start of training    \n",
    "     # Training loop\n",
    "    for epoch in range(hparams.epochs):      \n",
    "        hparams.epoch_accuracy_train = np.zeros(len(train_loader))\n",
    "        hparams.epoch_loss_train = np.zeros(len(train_loader))\n",
    "      \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # get a new batch of images and labels\n",
    "            data, target = batch\n",
    "            target = target.reshape(target.shape[0]).to(device)\n",
    "\n",
    "            # forward pass\n",
    "            output = model(data.to(device))\n",
    "            # TODO: Use the loss function on the output and target to get the train loss\n",
    "            loss = loss_function(output, target)\n",
    "\n",
    "            # backward pass\n",
    "            # TODO: reset the optimizer's gradients\n",
    "            optimizer.zero_grad()\n",
    "            # TODO: complete the backward\n",
    "            loss.backward()\n",
    "            # TODO: complete the algorithm step\n",
    "            optimizer.step()\n",
    "               \n",
    "            # save the loss and accuracy for the graph visualization\n",
    "            hparams.epoch_accuracy_train[i] = multi_class_accuracy(output, target)\n",
    "            hparams.epoch_loss_train[i] = loss.item()\n",
    "                \n",
    "            if (i == 0 and epoch == 0) or ((i+1) == iter_num):\n",
    "                torch.cuda.empty_cache()\n",
    "                model.eval()\n",
    "                test_loss, test_accuracy = evaluate(test_loader, model, loss_function)\n",
    "                print_performance(epoch, i, hparams, test_loss, test_accuracy)\n",
    "                model.train()\n",
    "\n",
    "            # TODO: Position A - should the scheduler.step() be here? Or...\n",
    "            # ----- end of batch loop -----\n",
    "        scheduler.step()\n",
    "        # TODO: Position B - should the scheduler.step() be here?\n",
    "        # ----- end of epoch loop -----\n",
    "\n",
    "    plt.show()\n",
    "    print(f\"Total training took {time.time() - start_time:.2f} seconds\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the evaluation function is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(test_loader, model, loss_function):\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            data, target = batch\n",
    "            output = model(data.to(device))\n",
    "            batch_loss = loss_function(output, target.to(device))\n",
    "            batch_acc = multi_class_accuracy(output, target.to(device))\n",
    "            loss+= batch_loss\n",
    "            acc+=batch_acc\n",
    "        return loss.item()/len(test_loader),acc/len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "Run the training loop and plot the loss and accuracy of the model on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch No. | Iter No. | Train Loss | Train Accuracy | Test Loss | Test Accuracy |\n",
      "----------------------------------------------------------------------------------\n",
      "|     0     |    1     |    2.31    |      0.08      |    2.3    |      0.1      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     0     |   200    |    2.14    |      0.32      |   2.08    |     0.38      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     1     |   200    |    2.04    |      0.42      |    2.0    |     0.46      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     2     |   200    |    1.98    |      0.47      |    2.0    |     0.46      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     3     |   200    |    1.96    |      0.49      |   1.95    |     0.51      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     4     |   200    |    1.94    |      0.52      |   1.92    |     0.54      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     5     |   200    |    1.93    |      0.53      |   1.95    |     0.51      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     6     |   200    |    1.88    |      0.57      |   1.96    |      0.5      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     7     |   200    |    1.86    |      0.6       |   1.87    |     0.59      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     8     |   200    |    1.81    |      0.65      |    1.8    |     0.66      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     9     |   200    |    1.8     |      0.66      |   1.79    |     0.66      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    10     |   200    |    1.79    |      0.67      |   1.83    |     0.63      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    11     |   200    |    1.78    |      0.68      |   1.77    |     0.69      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    12     |   200    |    1.77    |      0.69      |   1.77    |     0.69      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    13     |   200    |    1.77    |      0.69      |   1.79    |     0.67      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    14     |   200    |    1.76    |      0.7       |   1.75    |     0.71      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    15     |   200    |    1.75    |      0.71      |   1.72    |     0.74      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    16     |   200    |    1.73    |      0.73      |   1.72    |     0.74      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    17     |   200    |    1.72    |      0.74      |   1.72    |     0.74      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    18     |   200    |    1.71    |      0.75      |    1.7    |     0.75      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    19     |   200    |    1.71    |      0.75      |    1.7    |     0.76      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    20     |   200    |    1.7     |      0.76      |    1.7    |     0.76      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    21     |   200    |    1.7     |      0.76      |    1.7    |     0.76      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    22     |   200    |    1.7     |      0.77      |    1.7    |     0.76      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    23     |   200    |    1.69    |      0.77      |    1.7    |     0.76      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    24     |   200    |    1.68    |      0.78      |   1.68    |     0.78      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    25     |   200    |    1.67    |      0.79      |   1.68    |     0.78      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    26     |   200    |    1.67    |      0.79      |   1.67    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    27     |   200    |    1.67    |      0.79      |   1.67    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    28     |   200    |    1.67    |      0.79      |   1.67    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    29     |   200    |    1.67    |      0.79      |   1.67    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    30     |   200    |    1.66    |      0.8       |   1.67    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    31     |   200    |    1.66    |      0.8       |   1.67    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    32     |   200    |    1.66    |      0.8       |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    33     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    34     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    35     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    36     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    37     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    38     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    39     |   200    |    1.65    |      0.81      |   1.66    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "Total training took 164.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_with_scheduler(hparams=hparams, train_loader=train_loader, test_loader=test_loader,\n",
    "                     model=model, optimizer=optimizer, scheduler=scheduler, loss_function=loss_function)\n",
    "present_confusion_matrix(model, test_loader, class_names, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
