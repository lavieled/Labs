{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Lab: ECE-00450107\n",
    "## Meeting 1 - Part 3: The code breaking challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code in this file, make sure that you are **activating the enviourment** in which the following packages are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions and Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## DO NOT EDIT THIS CODE SECTION\n",
    "from DL_Lab1_functions import *\n",
    "import albumentations as A # for using augmentations. if not used you can remove this.\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "%matplotlib tk\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set fixed seeds to enable reproducing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the last ID digit of each student in the team\n",
    "id_digit1 = 319046504\n",
    "id_digit2 = 206492910\n",
    "seed = (id_digit1+id_digit2)%10\n",
    "\n",
    "####################################\n",
    "## DO NOT EDIT THIS CODE SECTION\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "train_flag = False\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Breaker!\n",
    "\n",
    "In this task we will build and train from scratch a fully-connected neural classifier on the 'EMNIST Letters' dataset.\n",
    "<center width=\"100%\"><img src=\"./assets/emnist.jpeg\" width=\"300px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load \"EMNIST Letters\" dataset and get to know it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set contains 124800 images, divided into 26 sections:\n",
      "The test set contains 20800 images, divided into 26 sections:\n",
      "Label 1: 800 examples\n",
      "Label 2: 800 examples\n",
      "Label 3: 800 examples\n",
      "Label 4: 800 examples\n",
      "Label 5: 800 examples\n",
      "Label 6: 800 examples\n",
      "Label 7: 800 examples\n",
      "Label 8: 800 examples\n",
      "Label 9: 800 examples\n",
      "Label 10: 800 examples\n",
      "Label 11: 800 examples\n",
      "Label 12: 800 examples\n",
      "Label 13: 800 examples\n",
      "Label 14: 800 examples\n",
      "Label 15: 800 examples\n",
      "Label 16: 800 examples\n",
      "Label 17: 800 examples\n",
      "Label 18: 800 examples\n",
      "Label 19: 800 examples\n",
      "Label 20: 800 examples\n",
      "Label 21: 800 examples\n",
      "Label 22: 800 examples\n",
      "Label 23: 800 examples\n",
      "Label 24: 800 examples\n",
      "Label 25: 800 examples\n",
      "Label 26: 800 examples\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train = torchvision.datasets.EMNIST(root=\"/usr/share/DL_exp/datasets/emnist-letters\", split='letters', train=True, download=True)\n",
    "test = torchvision.datasets.EMNIST(root=\"/usr/share/DL_exp/datasets/emnist-letters\", split='letters', train=False, download=True)\n",
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "\n",
    "# Count the number of samples in each category\n",
    "labels = [label for _, label in train]\n",
    "label_counts = Counter(labels)\n",
    "print(f\"The train set contains {train_size} images, divided into {len(label_counts.items())} sections:\")\n",
    "\n",
    "labels = [label for _, label in test]\n",
    "label_counts = Counter(labels)\n",
    "print(f\"The test set contains {test_size} images, divided into {len(label_counts.items())} sections:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normilize and save data in tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to tensors\n",
    "# need to remove 1 because the labels are 1-26 and the network expects 0-25\n",
    "train_data_notNorm = train.data.to(torch.float).to(device)\n",
    "train_labels = train.targets.to(device)-1 \n",
    "test_data_notNorm = test.data.to(torch.float).to(device)\n",
    "test_labels = test.targets.to(device)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value is 43.917964935302734\n",
      "The std value is 84.39138793945312\n"
     ]
    }
   ],
   "source": [
    "# get the mean and the std of the train set\n",
    "train_mean = torch.mean(train_data_notNorm)\n",
    "train_std = torch.std(train_data_notNorm)\n",
    "print(f\"The mean value is {train_mean}\")\n",
    "print(f\"The std value is {train_std}\")\n",
    "\n",
    "# normalize the train and test sets using mean and std\n",
    "train_data = (train_data_notNorm-train_mean)/train_std\n",
    "test_data = (test_data_notNorm-train_mean)/train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on - you are on your own... :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Fully Connected Neural Network Architeture Class \n",
    "class WeWantPrice(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_layer_size: int, output_size: int):\n",
    "        super(WeWantPrice, self).__init__()\n",
    "        # define the network fully connected layers\n",
    "        self.fc_layer1 = nn.Linear(input_size, 392)\n",
    "        self.fc_layer2 = nn.Linear(392, 196)\n",
    "        self.fc_layer3 = nn.Linear(196, output_size)\n",
    "        # define a flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        # define a sigmoid (activation) layer\n",
    "        self.activation = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # define the input layer, operating on flattaned inputs\n",
    "        flattened_x = self.flatten(x)\n",
    "        # define the first layer, using linear operation and then activation\n",
    "        z1 = self.fc_layer1(flattened_x)\n",
    "        z2 = self.activation(z1)\n",
    "        z2 = self.fc_layer2(z2)\n",
    "        z3 = self.activation(z2)\n",
    "        # define the output layer\n",
    "        return self.fc_layer3(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper-parameters\n",
    "hparams = Hyper_Params()\n",
    "hparams.train_size = train_size\n",
    "hparams.lr = 0.05\n",
    "hparams.batch_size = 30\n",
    "hparams.epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the network model with a hidden layer of size 200 and send to device\n",
    "model = WeWantPrice(input_size=784, hidden_layer_size=392, output_size=26).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=hparams.lr)\n",
    "# Define the loss criterion\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "| Epoch No. | Iter No. | Train Loss | Train Accuracy | Test Loss | Test Accuracy |\n",
      "----------------------------------------------------------------------------------\n",
      "|     0     |    1     |    3.22    |      0.0       |    3.3    |     0.05      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     0     |   4160   |    1.89    |      0.45      |   1.15    |     0.66      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     1     |   4160   |    0.94    |      0.72      |   0.77    |     0.78      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     2     |   4160   |    0.66    |      0.81      |   0.59    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     3     |   4160   |    0.51    |      0.85      |   0.48    |     0.86      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     4     |   4160   |    0.42    |      0.87      |   0.42    |     0.87      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     5     |   4160   |    0.37    |      0.89      |   0.38    |     0.88      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     6     |   4160   |    0.32    |      0.9       |   0.35    |     0.89      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     7     |   4160   |    0.29    |      0.91      |   0.33    |      0.9      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     8     |   4160   |    0.27    |      0.91      |   0.32    |      0.9      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     9     |   4160   |    0.25    |      0.92      |   0.31    |      0.9      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    10     |   4160   |    0.23    |      0.93      |   0.31    |      0.9      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    11     |   4160   |    0.22    |      0.93      |    0.3    |      0.9      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    12     |   4160   |    0.21    |      0.93      |    0.3    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    13     |   4160   |    0.19    |      0.94      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    14     |   4160   |    0.18    |      0.94      |    0.3    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    15     |   4160   |    0.17    |      0.94      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    16     |   4160   |    0.17    |      0.95      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    17     |   4160   |    0.16    |      0.95      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    18     |   4160   |    0.15    |      0.95      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    19     |   4160   |    0.14    |      0.95      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    20     |   4160   |    0.14    |      0.96      |    0.3    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    21     |   4160   |    0.13    |      0.96      |   0.29    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    22     |   4160   |    0.12    |      0.96      |   0.31    |      0.9      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    23     |   4160   |    0.12    |      0.96      |   0.31    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    24     |   4160   |    0.11    |      0.96      |    0.3    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    25     |   4160   |    0.11    |      0.96      |   0.31    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    26     |   4160   |    0.1     |      0.97      |   0.31    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    27     |   4160   |    0.1     |      0.97      |   0.31    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    28     |   4160   |    0.1     |      0.97      |   0.31    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    29     |   4160   |    0.09    |      0.97      |   0.32    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    30     |   4160   |    0.09    |      0.97      |   0.31    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    31     |   4160   |    0.09    |      0.97      |   0.32    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    32     |   4160   |    0.08    |      0.97      |   0.32    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    33     |   4160   |    0.08    |      0.97      |   0.33    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    34     |   4160   |    0.08    |      0.98      |   0.33    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    35     |   4160   |    0.07    |      0.98      |   0.33    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    36     |   4160   |    0.07    |      0.98      |   0.34    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    37     |   4160   |    0.07    |      0.98      |   0.34    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    38     |   4160   |    0.07    |      0.98      |   0.34    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    39     |   4160   |    0.06    |      0.98      |   0.34    |     0.91      |\n",
      "----------------------------------------------------------------------------------\n",
      "Total training took 140.03 seconds\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not train_flag:\n",
    "    print(\"Training started...\")\n",
    "    train_flag = True\n",
    "    \n",
    "    # Start a progress graph and a performance table, for visualization of the trainig process:\n",
    "    hparams.fig, (hparams.ax1, hparams.ax2) = plt.subplots(2, 1, figsize=(15, 9))\n",
    "    print_performance_grid(Flag=True)\n",
    "    # Calculate how many iterations the model trains in each epoch\n",
    "    iter_num = int(np.ceil(hparams.train_size/hparams.batch_size))\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    start_time = time.time() # time the start of training\n",
    "    # Training loop:\n",
    "    for epoch in range(hparams.epochs):\n",
    "        # for each epoch, do:\n",
    "        hparams.epoch_accuracy_train = np.zeros(iter_num)\n",
    "        hparams.epoch_loss_train = np.zeros(iter_num)\n",
    "        # randomly reshuffle the training and test groups before each new epoch:\n",
    "        index = torch.randperm(hparams.train_size)\n",
    "        train_data_perm = train_data[index]\n",
    "        train_labels_perm = train_labels[index]\n",
    "        # for each batch, do:\n",
    "        for i, batch in enumerate(range(0, hparams.train_size, hparams.batch_size)):\n",
    "            # Get a new batch of images and labels\n",
    "            data = train_data_perm[batch:batch+hparams.batch_size].to(device) \n",
    "            target = train_labels_perm[batch:batch+hparams.batch_size].squeeze().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data) # Apply the network on the new examples\n",
    "            loss = loss_function(output, target) # calculate the value of the loss function\n",
    "            \n",
    "            # Backward pass - ALWAYS IN THIS ORDER!\n",
    "            optimizer.zero_grad() # First, delete the gradients from the previous iteration\n",
    "            loss.backward() # Run backward pass on the loss\n",
    "            optimizer.step() # Preform an algorithm step (using the optimizer)\n",
    "    \n",
    "            # Save the loss and accuracy for the graph visualization\n",
    "            hparams.epoch_accuracy_train[i] = multi_class_accuracy(output, target.squeeze().to(device))\n",
    "            hparams.epoch_loss_train[i] = loss.item()\n",
    "            if(i == 0 and epoch == 0) or ((i+1) == iter_num):\n",
    "                # Freeze the model in order to evaluate the loss and accuracy on the test set\n",
    "                model.eval()\n",
    "                test_out = model(test_data)\n",
    "                test_loss = loss_function(test_out, test_labels.squeeze()).item()\n",
    "                test_accuracy = multi_class_accuracy(test_out, test_labels.squeeze())\n",
    "                print_performance(epoch, i, hparams, test_loss, test_accuracy)\n",
    "                model.train()\n",
    "                          \n",
    "    plt.show()\n",
    "    print(f\"Total training took {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "else:\n",
    "    print(\"Error: Please restart the kernel before running the train again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model achieved 0.91% accuracy on the test set.\n",
      "Model saved to letter_classifier.pth, normalization values were saved to norm_values.txt.\n"
     ]
    }
   ],
   "source": [
    "# Save normalization values for later use\n",
    "stat_path = \"norm_values.txt\"\n",
    "with open(stat_path, \"w\") as file:\n",
    "    file.write(f\"The mean value is  {train_mean:.2f}\\n\")\n",
    "    file.write(f\"The std value is {train_std:.2f}\\n\")\n",
    "\n",
    "# Save the model for later use\n",
    "model_path = \"letter_classifier.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Your model achieved {test_accuracy:.2f}% accuracy on the test set.\")\n",
    "\n",
    "print(f\"Model saved to {model_path}, normalization values were saved to {stat_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
