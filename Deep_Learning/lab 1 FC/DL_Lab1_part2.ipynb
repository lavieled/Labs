{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Lab: ECE-00450107\n",
    "## Meeting 1 - Part 2: Dealing with unbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code in this file, make sure that you are **activating the enviourment** in which the following packages are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions and Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## DO NOT EDIT THIS CODE SECTION\n",
    "from DL_Lab1_functions import *\n",
    "import albumentations as A\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "%matplotlib tk\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set fixed seeds to enable reproducing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the last ID digit of each student in the team\n",
    "id_digit1 = 206492910\n",
    "id_digit2 = 319046504\n",
    "seed = (id_digit1+id_digit2)%10\n",
    "\n",
    "####################################\n",
    "## DO NOT EDIT THIS CODE SECTION\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "train_flag = False\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the meeting we will use the \"MNIST-Fashion\" dataset.  \n",
    "For the pupose of learning, we will remove some of its samples and classes to craete a smaller and unbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the device and load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set contains 26700 images, divided into 6 sections:\n",
      "Label 0: T-shirt/top: 6000 examples\n",
      "Label 2: Pullover: 1500 examples\n",
      "Label 1: Trouser: 6000 examples\n",
      "Label 5: Shirt: 6000 examples\n",
      "Label 4: Coat: 6000 examples\n",
      "Label 3: Dress: 1200 examples\n",
      "The test set contains 6000 images, divided into 6 sections:\n",
      "Label 2: 1000 examples\n",
      "Label 1: 1000 examples\n",
      "Label 5: 1000 examples\n",
      "Label 4: 1000 examples\n",
      "Label 3: 1000 examples\n",
      "Label 0: 1000 examples\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "fulltrain = torchvision.datasets.FashionMNIST(root=\"/usr/share/DL_exp/datasets/mnist-fashion\",train=True, download=True)\n",
    "fulltest = torchvision.datasets.FashionMNIST(root=\"/usr/share/DL_exp/datasets/mnist-fashion\",train=False, download=True)\n",
    "\n",
    "###############################################################################################################################\n",
    "# Flags for code enabling/disabling:\n",
    "dataset_flag = 2 # 1-clothes balanced dataset, 2-clothes unbalanced dataset\n",
    "train_code_flag = 3 # 0-regular training, 1-training with oversampling, 2-training with weights, 3-training with augmentations\n",
    "###############################################################################################################################\n",
    "\n",
    "if(dataset_flag == 1):\n",
    "    train, test = fashion_mnist_leave_only_clothes(fulltrain, fulltest)\n",
    "    class_names = ['0: T-shirt/top', '1: Trouser', '2: Pullover', '3: Dress', '4: Coat', '5: Shirt']\n",
    "elif(dataset_flag == 2):\n",
    "    train, test = fashion_mnist_imbalanced(fulltrain, fulltest, seed=seed)\n",
    "    class_names = ['0: T-shirt/top', '1: Trouser', '2: Pullover', '3: Dress', '4: Coat', '5: Shirt']\n",
    "else:\n",
    "    print(\"Wrong flag value\")\n",
    "\n",
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "\n",
    "# Display dataset distribution - train and test\n",
    "labels1 = [label for _, label in train]\n",
    "label_counts1 = Counter(labels1)\n",
    "plot_counts1 = []\n",
    "plot_labels1 = []\n",
    "print(f\"The train set contains {train_size} images, divided into {len(label_counts1.items())} sections:\")\n",
    "for label, count in label_counts1.items():\n",
    "    print(f\"Label {class_names[label]}: {count} examples\")\n",
    "    plot_counts1.append(count)\n",
    "    plot_labels1.append(f\"class {label}:\\n{count} examples\")\n",
    "\n",
    "labels2 = [label for _, label in test]\n",
    "label_counts2 = Counter(labels2)\n",
    "plot_counts2 = []\n",
    "plot_labels2 = []\n",
    "print(f\"The test set contains {test_size} images, divided into {len(label_counts2.items())} sections:\")\n",
    "for label, count in label_counts2.items():\n",
    "    print(f\"Label {label}: {count} examples\")\n",
    "    plot_counts2.append(count)\n",
    "    plot_labels2.append(f\"class {label}:\\n{count} examples\")   \n",
    "        \n",
    "if train_code_flag == 0:\n",
    "    # Display a few samples\n",
    "    display_Mnist_Sample(train) \n",
    "\n",
    "    # Plot the Dataset as pie chart\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    axs[0].pie(plot_counts1, labels=plot_labels1, autopct='%1.1f%%', startangle=140)\n",
    "    axs[0].set_title('Class Distribution in Train Dataset')    \n",
    "    axs[1].pie(plot_counts2, labels=plot_labels2, autopct='%1.1f%%', startangle=140)\n",
    "    axs[1].set_title('Class Distribution in Test Dataset')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data in tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_to_tensor(subset, device):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for idx in range(len(subset)):\n",
    "        sample, label = subset[idx]\n",
    "        data.append(np.array(sample))\n",
    "        labels.append(label)\n",
    "    \n",
    "    data_tensor = torch.tensor(np.array(data), dtype=torch.float32).to(device)\n",
    "    labels_tensor = torch.tensor(np.array(labels), dtype=torch.long).to(device)    \n",
    "    \n",
    "    return data_tensor, labels_tensor\n",
    "\n",
    "train_data_notNorm, train_labels = subset_to_tensor(train, device)\n",
    "test_data_notNorm, test_labels = subset_to_tensor(test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following code (copy the rellevant parts from the previous file):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normilize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the code\n",
    "train_mean = torch.mean(train_data_notNorm)\n",
    "train_std = torch.std(train_data_notNorm)\n",
    "\n",
    "train_data = (train_data_notNorm-train_mean)/train_std\n",
    "test_data = (test_data_notNorm-train_mean)/train_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the class of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Fully Connected Neural Network Architeture Class \n",
    "class OurClothNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_layer_size: int, output_size: int):\n",
    "        super(OurClothNetwork, self).__init__()\n",
    "        # define the network fully connected layers\n",
    "        self.fc_layer1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.fc_layer2 = nn.Linear(hidden_layer_size, output_size)\n",
    "        # define a flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        # define a sigmoid (activation) layer\n",
    "        self.activation = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # define the input layer, operating on flattaned inputs\n",
    "        flattened_x = self.flatten(x)\n",
    "        # define the first layer, using linear operation and then activation\n",
    "        z1 = self.fc_layer1(flattened_x)\n",
    "        z2 = self.activation(z1)\n",
    "        # define the output layer\n",
    "        return self.fc_layer2(z2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyper-parameters that will be used during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper-parameters\n",
    "hparams = Hyper_Params()\n",
    "hparams.train_size = train_size\n",
    "hparams.lr = 0.3\n",
    "hparams.batch_size = 100\n",
    "hparams.epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model, and define Gradient Descend as optimizer and Cross Entropy for loss.  \n",
    "*Attention:* What are the sizes of the input and output layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the network model with a hidden layer of size 200 and send to device\n",
    "model = OurClothNetwork(input_size=784, hidden_layer_size=200, output_size=6).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=hparams.lr)\n",
    "# Define the loss criterion\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_code_flag == 0:\n",
    "    if not train_flag:\n",
    "        print(\"Training started...\")\n",
    "        train_flag = True\n",
    "        \n",
    "        # Start a progress graph and a performance table, for visualization of the trainig process:\n",
    "        hparams.fig, (hparams.ax1, hparams.ax2) = plt.subplots(2, 1, figsize=(15, 9))\n",
    "        print_performance_grid(Flag=True)\n",
    "        # Calculate how many iterations the model trains in each epoch\n",
    "        iter_num = int(np.ceil(hparams.train_size/hparams.batch_size))\n",
    "        \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        start_time = time.time() # time the start of training\n",
    "        # Training loop:\n",
    "        for epoch in range(hparams.epochs):\n",
    "            # for each epoch, do:\n",
    "            hparams.epoch_accuracy_train = np.zeros(iter_num)\n",
    "            hparams.epoch_loss_train = np.zeros(iter_num)\n",
    "            # randomly reshuffle the training and test groups before each new epoch:\n",
    "            index = torch.randperm(hparams.train_size)\n",
    "            train_data_perm = train_data[index]\n",
    "            train_labels_perm = train_labels[index]\n",
    "            # for each batch, do:\n",
    "            for i, batch in enumerate(range(0, hparams.train_size, hparams.batch_size)):\n",
    "                # Get a new batch of images and labels\n",
    "                data = train_data_perm[batch:batch+hparams.batch_size].to(device) \n",
    "                target = train_labels_perm[batch:batch+hparams.batch_size].squeeze().to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = model(data) # Apply the network on the new examples\n",
    "                loss = loss_function(output, target) # calculate the value of the loss function\n",
    "                \n",
    "                # Backward pass - ALWAYS IN THIS ORDER!\n",
    "                optimizer.zero_grad() # First, delete the gradients from the previous iteration\n",
    "                loss.backward() # Run backward pass on the loss\n",
    "                optimizer.step() # Preform an algorithm step (using the optimizer)\n",
    "        \n",
    "                # Save the loss and accuracy for the graph visualization\n",
    "                hparams.epoch_accuracy_train[i] = multi_class_accuracy(output, target.squeeze().to(device))\n",
    "                hparams.epoch_loss_train[i] = loss.item()\n",
    "                if(i == 0 and epoch == 0) or ((i+1) == iter_num):\n",
    "                    # Freeze the model in order to evaluate the loss and accuracy on the test set\n",
    "                    model.eval()\n",
    "                    test_out = model(test_data)\n",
    "                    test_loss = loss_function(test_out, test_labels.squeeze()).item()\n",
    "                    test_accuracy = multi_class_accuracy(test_out, test_labels.squeeze())\n",
    "                    print_performance(epoch, i, hparams, test_loss, test_accuracy)\n",
    "                    model.train()\n",
    "                              \n",
    "        plt.show()\n",
    "        print(f\"Total training took {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        print(\"Training finished.\")\n",
    "    else:\n",
    "        print(\"Error: Please restart the kernel before running the train again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model using random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_code_flag == 1:\n",
    "    if not train_flag:\n",
    "        print(\"Training with oversampling started...\")\n",
    "        train_flag = True\n",
    "        \n",
    "        num_of_classes = len(class_names)\n",
    "        # ------------------ Oversampling - Before train -----------------------\n",
    "        # a \"balanced\" batch should contain an equal number of samples from each class:\n",
    "        num_of_samples_in_batch_from_each_class = int(hparams.batch_size/num_of_classes) # (how many samples from each class should be in a 'balanced batch'?)\n",
    " \n",
    "        # Prepare a list of the indices for each class:\n",
    "        class_indices = [[] for _ in range(num_of_classes)] # initiate class indices with empty lists\n",
    "        for idx, label in enumerate(train_labels):\n",
    "            class_indices[label].append(idx) # insert index to the list of its class according to the label\n",
    "        \n",
    "        # make sure that batch_size represents the required number of samples\n",
    "        if(hparams.batch_size > num_of_samples_in_batch_from_each_class*num_of_classes):\n",
    "            num_of_samples_in_batch_from_each_class = num_of_samples_in_batch_from_each_class + 1\n",
    "            print(f\"Number of samples per class was increased to {num_of_samples_in_batch_from_each_class}.\")\n",
    "        if(hparams.batch_size < num_of_samples_in_batch_from_each_class*num_of_classes):\n",
    "            hparams.batch_size = num_of_samples_in_batch_from_each_class*num_of_classes\n",
    "            print(f\"Batch size was updated to {hparams.batch_size} so it will contain the same amount from each class.\")\n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "        # Start a progress graph and a performance table, for visualization of the trainig process:\n",
    "        hparams.fig, (hparams.ax1, hparams.ax2) = plt.subplots(2, 1, figsize=(15, 9))\n",
    "        print_performance_grid(Flag=True)\n",
    "        # Calculate how many iterations the model trains in each epoch\n",
    "        iter_num = int(np.ceil(hparams.train_size/hparams.batch_size))\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        start_time = time.time() # time the start of training\n",
    "        # Training loop:\n",
    "        for epoch in range(hparams.epochs):\n",
    "            # for each epoch, do:\n",
    "            hparams.epoch_accuracy_train = np.zeros(iter_num)\n",
    "            hparams.epoch_loss_train = np.zeros(iter_num)\n",
    "\n",
    "            # for each batch, do:\n",
    "            for i, batch in enumerate(range(0, hparams.train_size, hparams.batch_size)):\n",
    "                # --------------- Oversampling - During train --------------------------\n",
    "                # Get a new batch of images and labels\n",
    "                batch_indices = []\n",
    "                # for each class: randomly select the required amount of samples (from that class) to be included in the batch\n",
    "                for idx in range(num_of_classes):\n",
    "                    batch_indices.extend(np.random.choice(class_indices[idx], num_of_samples_in_batch_from_each_class, replace=False))\n",
    "                np.random.shuffle(batch_indices)\n",
    "                # ----------------------------------------------------------------------\n",
    "                data = train_data[batch_indices].to(device)\n",
    "                target = train_labels[batch_indices].squeeze().to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = model(data) # Apply the network on the new examples\n",
    "                loss = loss_function(output, target) # calculate the value of the loss function\n",
    "                \n",
    "                # Backward pass - ALWAYS IN THIS ORDER!\n",
    "                optimizer.zero_grad() # First, delete the gradients from the previous iteration\n",
    "                loss.backward() # Run backward pass on the loss\n",
    "                optimizer.step() # Preform an algorithm step (using the optimizer)\n",
    "        \n",
    "                # Save the loss and accuracy for the graph visualization\n",
    "                hparams.epoch_accuracy_train[i] = multi_class_accuracy(output, target.squeeze().to(device))\n",
    "                hparams.epoch_loss_train[i] = loss.item()\n",
    "                if(i == 0 and epoch == 0) or ((i+1) == iter_num):\n",
    "                    # Freeze the model in order to evaluate the loss and accuracy on the test set\n",
    "                    model.eval()\n",
    "                    test_out = model(test_data)\n",
    "                    test_loss = loss_function(test_out, test_labels.squeeze()).item()\n",
    "                    test_accuracy = multi_class_accuracy(test_out, test_labels.squeeze())\n",
    "                    print_performance(epoch, i, hparams, test_loss, test_accuracy)\n",
    "                    model.train()\n",
    "                              \n",
    "        plt.show()\n",
    "        print(f\"Total training took {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        print(\"Training finished.\")\n",
    "    else:\n",
    "        print(\"Error: Please restart the kernel before running the train again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model using weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_code_flag == 2:\n",
    "    if not train_flag:\n",
    "        print(\"Training with weights started...\")\n",
    "        train_flag = True\n",
    "        \n",
    "        num_of_classes = len(class_names)\n",
    "        # Start a progress graph and a performance table, for visualization of the training process:\n",
    "        hparams.fig, (hparams.ax1, hparams.ax2) = plt.subplots(2, 1, figsize=(15, 9))\n",
    "        print_performance_grid(Flag=True)\n",
    "        # Calculate how many iterations the model trains in each epoch\n",
    "        iter_num = int(np.ceil(hparams.train_size/hparams.batch_size))\n",
    "\n",
    "        # ------------------ Weighting - Before train -----------------------\n",
    "        # Prepare a list of the indices of each class (same as in oversampling):\n",
    "        class_indices = [[] for _ in range(num_of_classes)]\n",
    "        for idx, label in enumerate(train_labels):\n",
    "            class_indices[label].append(idx)\n",
    "            \n",
    "        # Calculate weights for each class based on their size:\n",
    "        class_weights = []\n",
    "        class_counts = []\n",
    "        for i in range(num_of_classes):\n",
    "            \n",
    "            count = len(class_indices[i]) \n",
    "            weight = 6000/count \n",
    "            print(weight)                   # Standard inverse frequency weighting\n",
    "            class_weights.append(weight)\n",
    "            class_counts.append(count)\n",
    "\n",
    "        class_weights = torch.FloatTensor(class_weights).to(device) # Convert to torch tensor\n",
    "        weighted_loss_function = nn.CrossEntropyLoss(weight=class_weights) # Create weighted loss function\n",
    "        # --------------------------------------------------------------------\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        start_time = time.time() # time the start of training\n",
    "        # Training loop:\n",
    "        for epoch in range(hparams.epochs):\n",
    "            # for each epoch, do:\n",
    "            hparams.epoch_accuracy_train = np.zeros(iter_num)\n",
    "            hparams.epoch_loss_train = np.zeros(iter_num)\n",
    "            # randomly reshuffle the training and test groups before each new epoch:\n",
    "            index = torch.randperm(hparams.train_size)\n",
    "            train_data_perm = train_data[index]\n",
    "            train_labels_perm = train_labels[index]\n",
    "            # for each batch, do:\n",
    "            for i, batch in enumerate(range(0, hparams.train_size, hparams.batch_size)):\n",
    "                # Get a new batch of images and labels\n",
    "                data = train_data_perm[batch:batch+hparams.batch_size].to(device) \n",
    "                target = train_labels_perm[batch:batch+hparams.batch_size].squeeze().to(device)\n",
    "                \n",
    "                # --------------- Weighting - During train --------------------------\n",
    "                # Forward pass\n",
    "                output = model(data)\n",
    "                loss = weighted_loss_function(output, target)\n",
    "                # -------------------------------------------------------------\n",
    "                \n",
    "                # Backward pass - ALWAYS IN THIS ORDER!\n",
    "                optimizer.zero_grad() # First, delete the gradients from the previous iteration\n",
    "                loss.backward() # Run backward pass on the loss\n",
    "                optimizer.step() # Perform an algorithm step (using the optimizer)\n",
    "        \n",
    "                # Save the loss and accuracy for the graph visualization\n",
    "                hparams.epoch_accuracy_train[i] = multi_class_accuracy(output, target)\n",
    "                hparams.epoch_loss_train[i] = loss.item()\n",
    "                \n",
    "                if(i == 0 and epoch == 0) or ((i+1) == iter_num):\n",
    "                    # Freeze the model in order to evaluate the loss and accuracy on the test set\n",
    "                    model.eval()\n",
    "                    test_out = model(test_data)\n",
    "                    test_loss = weighted_loss_function(test_out, test_labels.squeeze()).item()\n",
    "                    test_accuracy = multi_class_accuracy(test_out, test_labels.squeeze())\n",
    "                    print_performance(epoch, i, hparams, test_loss, test_accuracy)\n",
    "                    model.train()\n",
    "                              \n",
    "        plt.show()\n",
    "        print(f\"Total training took {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        print(\"Training finished.\")\n",
    "        \n",
    "        print(\"Classes distribution:\", class_counts)\n",
    "        print(\"Classes weights:\", class_weights.cpu().numpy())        \n",
    "    else:\n",
    "        print(\"Error: Please restart the kernel before running the train again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that uses off-line augmentation for balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_balance_dataset(dataset, device):\n",
    "\n",
    "    # save images and labels as NUMPY arrays\n",
    "    images = []\n",
    "    labels = []\n",
    "    for idx in range(len(dataset)):\n",
    "        im, lb = dataset[idx]\n",
    "        images.append(np.array(im))\n",
    "        labels.append(lb)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    # find the different sizes of each class\n",
    "    class_counts = Counter(labels)\n",
    "    max_class_count = max(class_counts.values())\n",
    "    \n",
    "    # define augmentations\n",
    "    # replace each ??? with a name of an augmentation function from the list in the booklet\n",
    "    # transform = A.Compose([A.???()])\n",
    "    # or\n",
    "    # transform = A.Compose([A.???(),A.???()])\n",
    "    transform = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomGamma()])\n",
    "\n",
    "\n",
    "\n",
    "    if len(transform.transforms) > 0: # verify that at least one augmentation was defined\n",
    "         # create a list containing the augmented copies\n",
    "        augmented_images = []\n",
    "        augmented_labels = []\n",
    "        class_items = list(class_counts.items())\n",
    "        num_of_classes = len(class_counts)\n",
    "        \n",
    "        # add augmentation to the smaller classes in order to create a balanced dataset\n",
    "        for i in range(num_of_classes):\n",
    "            class_label, count = class_items[i] # 'count' holds the amount of samples in the class, and 'class_label' holds the label of the class\n",
    "            if count < max_class_count:\n",
    "                num_of_augments_per_class = max_class_count-count  # calculate the number of augmented copies that should be added to each class\n",
    "                class_indices = np.where(labels == class_label)[0] # find the class's samples\n",
    "                for _ in range(num_of_augments_per_class):\n",
    "                    image_idx = np.random.choice(class_indices) # randomly select a sample\n",
    "                    augmented = transform(image=images[image_idx])['image'] # craete an augmented copy of the sample\n",
    "                    augmented_images.append(augmented) # add the augmented copy to the list\n",
    "                    augmented_labels.append(class_label)\n",
    "    \n",
    "        # add the augmented images to the original dataset\n",
    "        augmented_images = np.array(augmented_images)\n",
    "        augmented_labels = np.array(augmented_labels)\n",
    "        \n",
    "        images = np.concatenate([images, augmented_images])\n",
    "        labels = np.concatenate([labels, augmented_labels])\n",
    "    \n",
    "    # convet data to Tensors and create united dataset\n",
    "    images_tensor = torch.tensor(images, dtype=torch.float32).to(device)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "    return images_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model using augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with augmentations started...\n",
      "| Epoch No. | Iter No. | Train Loss | Train Accuracy | Test Loss | Test Accuracy |\n",
      "----------------------------------------------------------------------------------\n",
      "|     0     |    1     |    1.82    |      0.13      |   1.94    |     0.17      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     0     |   360    |    0.7     |      0.73      |   0.65    |     0.75      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     1     |   360    |    0.52    |      0.8       |   0.55    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     2     |   360    |    0.47    |      0.82      |   0.57    |     0.79      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     3     |   360    |    0.44    |      0.84      |   0.55    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     4     |   360    |    0.41    |      0.85      |   0.52    |     0.81      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     5     |   360    |    0.39    |      0.85      |   0.52    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     6     |   360    |    0.37    |      0.86      |   0.54    |      0.8      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     7     |   360    |    0.35    |      0.87      |   0.48    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     8     |   360    |    0.34    |      0.87      |    0.5    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|     9     |   360    |    0.32    |      0.88      |   0.51    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    10     |   360    |    0.31    |      0.88      |   0.48    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    11     |   360    |    0.3     |      0.89      |   0.51    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    12     |   360    |    0.29    |      0.89      |   0.49    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    13     |   360    |    0.28    |      0.9       |    0.5    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    14     |   360    |    0.27    |      0.9       |   0.48    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    15     |   360    |    0.25    |      0.91      |   0.51    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    16     |   360    |    0.25    |      0.91      |   0.49    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    17     |   360    |    0.24    |      0.91      |   0.49    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    18     |   360    |    0.23    |      0.92      |   0.57    |     0.81      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    19     |   360    |    0.22    |      0.92      |    0.5    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    20     |   360    |    0.21    |      0.92      |   0.52    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    21     |   360    |    0.2     |      0.93      |    0.5    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    22     |   360    |    0.2     |      0.93      |   0.51    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    23     |   360    |    0.19    |      0.93      |   0.55    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    24     |   360    |    0.18    |      0.94      |   0.55    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    25     |   360    |    0.18    |      0.94      |   0.53    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    26     |   360    |    0.17    |      0.94      |   0.58    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    27     |   360    |    0.16    |      0.94      |   0.54    |     0.83      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    28     |   360    |    0.16    |      0.94      |   0.58    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "|    29     |   360    |    0.15    |      0.95      |   0.56    |     0.82      |\n",
      "----------------------------------------------------------------------------------\n",
      "Total training took 9.11 seconds\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "if train_code_flag == 3:\n",
    "    if not train_flag:\n",
    "        print(\"Training with augmentations started...\")\n",
    "        train_flag = True\n",
    "\n",
    "        train_data_aug_notNorm, train_labels_aug = augment_and_balance_dataset(train, device) # expand the training set with augmentations\n",
    "        # since we changed the traning set, we want to re-calculate new mean and std values and normilize the dataset again\n",
    "        train_mean_aug = torch.mean(train_data_aug_notNorm)\n",
    "        train_std_aug = torch.std(train_data_aug_notNorm)\n",
    "        train_data_aug = (train_data_aug_notNorm-train_mean_aug)/train_std_aug\n",
    "        test_data = (test_data_notNorm-train_mean_aug)/train_std_aug        \n",
    "\n",
    "        hparams.train_size = len(train_data_aug)\n",
    "\n",
    "        # Start a progress graph and a performance table, for visualization of the trainig process:\n",
    "        hparams.fig, (hparams.ax1, hparams.ax2) = plt.subplots(2, 1, figsize=(15, 9))\n",
    "        print_performance_grid(Flag=True)\n",
    "        # Calculate how many iterations the model trains in each epoch\n",
    "        iter_num = int(np.ceil(hparams.train_size/hparams.batch_size))\n",
    "       \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        start_time = time.time() # time the start of training\n",
    "        # Training loop:\n",
    "        for epoch in range(hparams.epochs):\n",
    "            # for each epoch, do:\n",
    "            hparams.epoch_accuracy_train = np.zeros(iter_num)\n",
    "            hparams.epoch_loss_train = np.zeros(iter_num)\n",
    "            # randomly reshuffle the training and test groups before each new epoch:\n",
    "            index = torch.randperm(hparams.train_size)\n",
    "            train_data_perm = train_data_aug[index]\n",
    "            train_labels_perm = train_labels_aug[index]\n",
    "            # for each batch, do:\n",
    "            for i, batch in enumerate(range(0, hparams.train_size, hparams.batch_size)):\n",
    "                # Get a new batch of images and labels\n",
    "                data = train_data_perm[batch:batch+hparams.batch_size].to(device) \n",
    "                target = train_labels_perm[batch:batch+hparams.batch_size].squeeze().to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = model(data) # Apply the network on the new examples\n",
    "                loss = loss_function(output, target) # calculate the value of the loss function\n",
    "                \n",
    "                # Backward pass - ALWAYS IN THIS ORDER!\n",
    "                optimizer.zero_grad() # First, delete the gradients from the previous iteration\n",
    "                loss.backward() # Run backward pass on the loss\n",
    "                optimizer.step() # Preform an algorithm step (using the optimizer)\n",
    "        \n",
    "                # Save the loss and accuracy for the graph visualization\n",
    "                hparams.epoch_accuracy_train[i] = multi_class_accuracy(output, target.squeeze().to(device))\n",
    "                hparams.epoch_loss_train[i] = loss.item()\n",
    "                if(i == 0 and epoch == 0) or ((i+1) == iter_num):\n",
    "                    # Freeze the model in order to evaluate the loss and accuracy on the test set\n",
    "                    model.eval()\n",
    "                    test_out = model(test_data)\n",
    "                    test_loss = loss_function(test_out, test_labels.squeeze()).item()\n",
    "                    test_accuracy = multi_class_accuracy(test_out, test_labels.squeeze())\n",
    "                    print_performance(epoch, i, hparams, test_loss, test_accuracy)\n",
    "                    model.train()\n",
    "                              \n",
    "        plt.show()\n",
    "        print(f\"Total training took {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        print(\"Training finished.\")\n",
    "    else:\n",
    "        print(\"Error: Please restart the kernel before running the train again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set, and calculate measures for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set's total accuarcy is:  0.82\n",
      "Class: 0: T-shirt/top Measures: Precision: 0.86, Recall: 0.76\n",
      "Class: 1: Trouser Measures: Precision: 0.99, Recall: 0.97\n",
      "Class: 2: Pullover Measures: Precision: 0.84, Recall: 0.73\n",
      "Class: 3: Dress Measures: Precision: 0.88, Recall: 0.87\n",
      "Class: 4: Coat Measures: Precision: 0.77, Recall: 0.82\n",
      "Class: 5: Shirt Measures: Precision: 0.64, Recall: 0.79\n"
     ]
    }
   ],
   "source": [
    "test_out = model(test_data)\n",
    "test_true = test_labels.squeeze()\n",
    "_, test_predicted = torch.max(test_out, dim=1)\n",
    "correct = (test_predicted == test_true).sum().item()\n",
    "accuracy = correct / test_true.size(0)\n",
    "\n",
    "cm = confusion_matrix(test_true.cpu(), test_predicted.cpu())\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = class_names)\n",
    "cm_display.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "accuracy = correct / test_true.size(0)\n",
    "precision = precision_score(test_true.cpu(), test_predicted.cpu(), average=None)\n",
    "recall = recall_score(test_true.cpu(), test_predicted.cpu(), average=None)\n",
    "print(f\"Test Set's total accuarcy is: {accuracy: .2f}\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"Class: {class_names[i]} Measures: Precision: {precision[i]:.2f}, Recall: {recall[i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
